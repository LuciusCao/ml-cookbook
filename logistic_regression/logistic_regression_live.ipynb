{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "print(data.target_names)\n",
    "\n",
    "X = data.data[:100]\n",
    "Y = data.target[:100]\n",
    "\n",
    "Y = Y.reshape(Y.shape[0], 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, Y_train.reshape(-1))\n",
    "logistic_regression.predict(X_test) == Y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01798620996209156"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(X, theta, bias):\n",
    "    dot_product = np.dot(X, theta) + bias\n",
    "    return sigmoid(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba(0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, theta, bias, Y):\n",
    "    predicted = predict_proba(X, theta, bias)\n",
    "    cost_total = - Y * np.log(predicted) - (1 - Y) * np.log(1 - predicted)\n",
    "    return np.mean(cost_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, theta, bias, Y):\n",
    "    # X: (80, 4)\n",
    "    # Y: (80, 1)\n",
    "    # theta: (4, 1)\n",
    "    predicted = predict_proba(X, theta, bias)\n",
    "    diff = predicted - Y\n",
    "    grad_theta = np.dot(X.T, diff) / len(diff)\n",
    "    # grad_theta = np.mean(np.multiply(diff, X), axis=0, keepdims=True)\n",
    "    grad_bias = np.mean(diff)\n",
    "    return grad_theta, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n",
      "1.032645173004043\n",
      "20.179597475330695\n",
      "6.608867698777141\n",
      "13.166764938338266\n",
      "nan\n",
      "6.154121646440696\n",
      "nan\n",
      "0.3782569862590067\n",
      "2.8427527002123558e-05\n",
      "2.8365529560013384e-05\n",
      "2.830380526771e-05\n",
      "2.8242352324074187e-05\n",
      "2.818116894374176e-05\n",
      "2.8120253357017744e-05\n",
      "2.8059603809692828e-05\n",
      "2.7999218562840455e-05\n",
      "2.7939095892686025e-05\n",
      "2.7879234090445597e-05\n",
      "2.7819631462120178e-05\n",
      "2.776028632837883e-05\n",
      "2.7701197024394624e-05\n",
      "2.7642361899676402e-05\n",
      "2.7583779317899174e-05\n",
      "2.7525447656781695e-05\n",
      "2.746736530793353e-05\n",
      "2.7409530676704865e-05\n",
      "2.7351942182004483e-05\n",
      "2.7294598256202255e-05\n",
      "2.7237497344955472e-05\n",
      "2.718063790712389e-05\n",
      "2.712401841451689e-05\n",
      "2.7067637351905706e-05\n",
      "2.701149321675812e-05\n",
      "2.6955584519168763e-05\n",
      "2.689990978168133e-05\n",
      "2.684446753925076e-05\n",
      "2.678925633902239e-05\n",
      "2.67342747402651e-05\n",
      "2.6679521314158728e-05\n",
      "2.6624994643763333e-05\n",
      "2.6570693323856573e-05\n",
      "2.651661596084466e-05\n",
      "2.646276117257064e-05\n",
      "2.6409127588266982e-05\n",
      "2.635571384840825e-05\n",
      "2.630251860460404e-05\n",
      "2.6249540519469693e-05\n",
      "2.619677826653591e-05\n",
      "2.6144230530159692e-05\n",
      "2.6091896005304895e-05\n",
      "2.6039773397586424e-05\n",
      "2.5987861423056344e-05\n",
      "2.593615880812594e-05\n",
      "2.5884664289483655e-05\n",
      "2.5833376613981132e-05\n",
      "2.5782294538470617e-05\n",
      "2.5731416829839492e-05\n",
      "2.5680742264746434e-05\n",
      "2.5630269629676703e-05\n",
      "2.5579997720742152e-05\n",
      "2.5529925343593636e-05\n",
      "2.54800513134139e-05\n",
      "2.543037445468699e-05\n",
      "2.5380893601242577e-05\n",
      "2.533160759603924e-05\n",
      "2.528251529120177e-05\n",
      "2.5233615547792083e-05\n",
      "2.5184907235868687e-05\n",
      "2.5136389234270033e-05\n",
      "2.508806043061162e-05\n",
      "2.5039919721159537e-05\n",
      "2.499196601076231e-05\n",
      "2.494419821275777e-05\n",
      "2.4896615248917415e-05\n",
      "2.4849216049326896e-05\n",
      "2.480199955232482e-05\n",
      "2.475496470443047e-05\n",
      "2.470811046025064e-05\n",
      "2.466143578242125e-05\n",
      "2.4614939641485085e-05\n",
      "2.4568621015879152e-05\n",
      "2.4522478891824914e-05\n",
      "2.447651226325604e-05\n",
      "2.4430720131739113e-05\n",
      "2.4385101506416646e-05\n",
      "2.4339655403920922e-05\n",
      "2.4294380848341906e-05\n",
      "2.4249276871056485e-05\n",
      "2.4204342510803242e-05\n",
      "2.4159576813513058e-05\n",
      "2.411497883223266e-05\n",
      "2.407054762715504e-05\n",
      "2.402628226544586e-05\n",
      "2.398218182123918e-05\n",
      "2.3938245375536056e-05\n",
      "2.389447201621273e-05\n",
      "2.3850860837844303e-05\n",
      "2.3807410941729593e-05\n",
      "2.376412143583413e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucius/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/lucius/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 2.4\n",
    "max_iter = 100\n",
    "\n",
    "theta = np.zeros((X.shape[1], 1))\n",
    "bias = 0\n",
    "\n",
    "for i in range(max_iter):\n",
    "    cost = cost_function(X_train, theta, bias, Y_train)\n",
    "    grad_theta, grad_bias = gradient(X_train, theta, bias, Y_train)\n",
    "    theta -= learning_rate * grad_theta\n",
    "    bias -= learning_rate * grad_bias\n",
    "    if i % 1 == 0:\n",
    "        print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict_proba(X_test, theta, bias) >= 0.5) == Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
